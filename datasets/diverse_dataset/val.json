[
  {
    "id": "prompt_000326",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000545",
    "difficulty": "easy",
    "language": "javascript",
    "task_description": "The javascript project has failing tests. The issue is straightforward - locate the problem and fix it. Files: utils.js, test_utils.js",
    "files": [
      {
        "path": "utils.js",
        "content": "// Utility functions\n\nfunction add(a, b) \n    return a + b;\n}\n\nfunction multiply(a, b) {\n    return a * b;\n}\n\nfunction isEven(n) {\n    return n % 2 === 0;\n}\n\nfunction capitalize(str) {\n    return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\nfunction range(start, end) {\n    const result = [];\n    for (let i = start; i <= end; i++) {\n        result.push(i);\n    }\n    return result;\n}\n\nmodule.exports = { add, multiply, isEven, capitalize, range };\n",
        "is_test": false
      },
      {
        "path": "test_utils.js",
        "content": "// Tests for utility functions\n\nconst { add, multiply, isEven, capitalize, range } = require('./utils');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_add() {\n    assertEquals(add(2, 3), 5, \"add(2, 3)\");\n    assertEquals(add(-1, 1), 0, \"add(-1, 1)\");\n    console.log(\"\u2713 test_add passed\");\n}\n\nfunction test_multiply() {\n    assertEquals(multiply(4, 5), 20, \"multiply(4, 5)\");\n    assertEquals(multiply(-2, 3), -6, \"multiply(-2, 3)\");\n    console.log(\"\u2713 test_multiply passed\");\n}\n\nfunction test_isEven() {\n    assertEquals(isEven(4), true, \"isEven(4)\");\n    assertEquals(isEven(5), false, \"isEven(5)\");\n    console.log(\"\u2713 test_isEven passed\");\n}\n\nfunction test_capitalize() {\n    assertEquals(capitalize(\"hello\"), \"Hello\", \"capitalize('hello')\");\n    assertEquals(capitalize(\"world\"), \"World\", \"capitalize('world')\");\n    console.log(\"\u2713 test_capitalize passed\");\n}\n\nfunction test_range() {\n    assertEquals(range(1, 5), [1, 2, 3, 4, 5], \"range(1, 5)\");\n    assertEquals(range(0, 0), [0], \"range(0, 0)\");\n    console.log(\"\u2713 test_range passed\");\n}\n\n// Run all tests\ntry {\n    test_add();\n    test_multiply();\n    test_isEven();\n    test_capitalize();\n    test_range();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls",
      "utils.js test_utils.js"
    ],
    "expected_commands": 3,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_utils.js",
        "description": "Tests must run successfully (exit code 0)"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3"
      ],
      "scenario_type": "utils"
    }
  },
  {
    "id": "prompt_000283",
    "difficulty": "medium",
    "language": "javascript",
    "task_description": "There's a bug in the javascript code that needs fixing. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: validators.js, test_validators.js",
    "files": [
      {
        "path": "validators.js",
        "content": "// Validation functions\n\nfunction isValidEmail(email) \n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n}\n\nfunction isValidPhone(phone) {\n    const regex = /^\\d{3}-\\d{3}-\\d{4}$/;\n    return regex.test(phone);\n}\n\nfunction isValidPassword(password) {\n    return password.length >= 8;\n}\n\nfunction isValidUsername(username) {\n    const regex = /^[a-zA-Z0-9_]{3,20}$/;\n    return regex.test(username);\n}\n\nmodule.exports = { isValidEmail, isValidPhone, isValidPassword, isValidUsername };\n",
        "is_test": false
      },
      {
        "path": "test_validators.js",
        "content": "// Tests for validators\n\nconst { isValidEmail, isValidPhone, isValidPassword, isValidUsername } = require('./validators');\n\nfunction assertEquals(actual, expected, message) {\n    if (actual !== expected) {\n        throw new Error(`${message}: expected ${expected}, got ${actual}`);\n    }\n}\n\nfunction test_isValidEmail() {\n    assertEquals(isValidEmail(\"user@example.com\"), true, \"valid email\");\n    assertEquals(isValidEmail(\"invalid\"), false, \"invalid email\");\n    console.log(\"\u2713 test_isValidEmail passed\");\n}\n\nfunction test_isValidPhone() {\n    assertEquals(isValidPhone(\"123-456-7890\"), true, \"valid phone\");\n    assertEquals(isValidPhone(\"1234567890\"), false, \"invalid phone\");\n    console.log(\"\u2713 test_isValidPhone passed\");\n}\n\nfunction test_isValidPassword() {\n    assertEquals(isValidPassword(\"password123\"), true, \"valid password\");\n    assertEquals(isValidPassword(\"short\"), false, \"invalid password\");\n    console.log(\"\u2713 test_isValidPassword passed\");\n}\n\nfunction test_isValidUsername() {\n    assertEquals(isValidUsername(\"user_123\"), true, \"valid username\");\n    assertEquals(isValidUsername(\"ab\"), false, \"too short username\");\n    console.log(\"\u2713 test_isValidUsername passed\");\n}\n\n// Run all tests\ntry {\n    test_isValidEmail();\n    test_isValidPhone();\n    test_isValidPassword();\n    test_isValidUsername();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 512 Oct 30 10:00 validators.js",
      "-rw-r--r-- 1 user user 1442 Oct 30 10:00 test_validators.js"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_validators.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3"
      ],
      "scenario_type": "validators"
    }
  },
  {
    "id": "prompt_000293",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000197",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000205",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000328",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000214",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Fix log analyzer using piping commands.\n\nAnalyze logs with pipes:\n1. cat server.log | grep ERROR (see errors)\n2. cat server.log | grep ERROR | wc -l (count errors)\n3. cat server.log | cut -d' ' -f4 | sort | uniq (unique levels)\n4. grep ERROR server.log | cut -d' ' -f1-2 (error timestamps)\n\nFix the code:\nsed -i 's/count += 1/if \"ERROR\" in line:\\n                count += 1/g' analyzer.py",
    "files": [
      {
        "path": "server.log",
        "content": "2024-10-30 10:00:00 INFO Server started\n2024-10-30 10:00:01 INFO Connected to database\n2024-10-30 10:00:05 ERROR Failed to load config\n2024-10-30 10:00:10 WARNING Retry attempt 1\n2024-10-30 10:00:15 ERROR Connection timeout\n2024-10-30 10:00:20 INFO Request processed\n2024-10-30 10:00:25 ERROR Database query failed\n",
        "is_test": false
      },
      {
        "path": "analyzer.py",
        "content": "\"\"\"Log analyzer with bug.\"\"\"\n\ndef count_errors(filename):\n    # BUG: Counts all lines, not just errors\n    count = 0\n    with open(filename) as f:\n        for line in f:\n            count += 1  # Should filter for ERROR\n    return count\n",
        "is_test": false
      },
      {
        "path": "test_analyzer.py",
        "content": "from analyzer import count_errors\n\ndef test_count():\n    result = count_errors('server.log')\n    assert result == 3, f\"Expected 3 errors, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "head server.log"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_analyzer.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "piping",
      "command_focus": "pipes"
    }
  },
  {
    "id": "prompt_000654",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "The javascript project has failing tests. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: utils.js, test_utils.js",
    "files": [
      {
        "path": "utils.js",
        "content": "// Utility functions\n\nfunction add(a, b) {\n    return a - b;\n}\n\nfunction multiply(a, b) {\n    return a * b;\n}\n\nfunction isEven(n) {\n    return n % 2 !!= 0;\n}\n\nfunction capitalize(str) {\n    return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\nfunction range(start, end) {\n    const result = [];\n    for (let i = start; i <= end; i++) {\n        result.push(i);\n    }\n    return result;\n}\n\nmodule.exports = { add, multiply, isEven, capitalize, range };\n",
        "is_test": false
      },
      {
        "path": "test_utils.js",
        "content": "// Tests for utility functions\n\nconst { add, multiply, isEven, capitalize, range } = require('./utils');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_add() {\n    assertEquals(add(2, 3), 5, \"add(2, 3)\");\n    assertEquals(add(-1, 1), 0, \"add(-1, 1)\");\n    console.log(\"\u2713 test_add passed\");\n}\n\nfunction test_multiply() {\n    assertEquals(multiply(4, 5), 20, \"multiply(4, 5)\");\n    assertEquals(multiply(-2, 3), -6, \"multiply(-2, 3)\");\n    console.log(\"\u2713 test_multiply passed\");\n}\n\nfunction test_isEven() {\n    assertEquals(isEven(4), true, \"isEven(4)\");\n    assertEquals(isEven(5), false, \"isEven(5)\");\n    console.log(\"\u2713 test_isEven passed\");\n}\n\nfunction test_capitalize() {\n    assertEquals(capitalize(\"hello\"), \"Hello\", \"capitalize('hello')\");\n    assertEquals(capitalize(\"world\"), \"World\", \"capitalize('world')\");\n    console.log(\"\u2713 test_capitalize passed\");\n}\n\nfunction test_range() {\n    assertEquals(range(1, 5), [1, 2, 3, 4, 5], \"range(1, 5)\");\n    assertEquals(range(0, 0), [0], \"range(0, 0)\");\n    console.log(\"\u2713 test_range passed\");\n}\n\n// Run all tests\ntry {\n    test_add();\n    test_multiply();\n    test_isEven();\n    test_capitalize();\n    test_range();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 452 Oct 30 10:00 utils.js",
      "-rw-r--r-- 1 user user 1486 Oct 30 10:00 test_utils.js",
      "$ node test_utils.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_utils.js",
        "description": "Tests must run successfully (exit code 0)"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong arithmetic operator on line 4",
        "Wrong comparison operator on line 12",
        "Wrong comparison operator on line 12"
      ],
      "scenario_type": "utils"
    }
  },
  {
    "id": "prompt_000813",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix the CSV processor that fails on the header line.\n\nExplore the data first:\n1. cat data.csv\n2. head -n 1 data.csv (see header)\n3. tail -n +2 data.csv (see data without header)\n4. cut -d',' -f3 data.csv (extract scores)\n5. awk -F',' 'NR>1 {print $3}' data.csv (scores without header)\n\nFix by skipping header:\nsed -i '/for line in f:/a\\        next(f)  # Skip header' processor.py",
    "files": [
      {
        "path": "data.csv",
        "content": "name,age,score\nAlice,25,85\nBob,30,92\nCharlie,22,78\nDavid,35,95\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "\"\"\"Process CSV data.\"\"\"\n\ndef process_data(filename):\n    # BUG: Doesn't handle header correctly\n    total = 0\n    with open(filename) as f:\n        for line in f:\n            parts = line.strip().split(',')\n            total += int(parts[2])  # Will fail on header\n    return total\n",
        "is_test": false
      },
      {
        "path": "test_processor.py",
        "content": "from processor import process_data\n\ndef test_process():\n    result = process_data('data.csv')\n    assert result == 350, f\"Expected 350, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat data.csv | head -3"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_processor.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "awk_cut",
      "command_focus": "awk,cut"
    }
  },
  {
    "id": "prompt_000776",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "The python project has failing tests. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b)\n    \"\"\"Add two numbers.\"\"\"\n    return a - b\n\ndef subtract(a, b)\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 430 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong arithmetic operator on line 5",
        "Missing colon on line 3",
        "Missing colon on line 7"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000908",
    "difficulty": "very_hard",
    "language": "javascript",
    "task_description": "Fix bugs with multiple sed commands.\n\nUse:\n1. sed -i 's/a - b/a + b/g' calculator.js\n2. sed -i 's/x + y/x \\* y/g' calculator.js\n3. sed -i '/DEBUG/d' calculator.js",
    "files": [
      {
        "path": "calculator.js",
        "content": "// Module with bugs\n\nfunction calculate(a, b) {\n    // BUG: Wrong operator\n    return a - b;  // Should be a + b\n}\n\nfunction multiply(x, y) {\n    // BUG: Wrong operator\n    return x + y;  // Should be x * y\n}\n\n// DEBUG\nconsole.log(\"DEBUG: Loading\");\n\nmodule.exports = { calculate, multiply };\n",
        "is_test": false
      },
      {
        "path": "test_calculator.js",
        "content": "const { calculate, multiply } = require('./calculator');\n\nif (calculate(5, 3) !== 8) throw new Error(\"calculate failed\");\nif (multiply(4, 5) !== 20) throw new Error(\"multiply failed\");\nconsole.log(\"\u2713 All tests passed\");\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.js",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000023",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000319",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000763",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "There's a bug in the javascript code that needs fixing. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: utils.js, test_utils.js",
    "files": [
      {
        "path": "utils.js",
        "content": "// Utility functions\n\nfunction add(a, b) \n    return a + b;\n}\n\nfunction multiply(a, b) \n    return a * b;\n}\n\nfunction isEven(n) {\n    return n % 2 === 0;\n}\n\nfunction capitalize(str) {\n    return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\nfunction range(start, end) {\n    const result = [];\n    for (let i = start; i <= end; i++) {\n        result.push(i);\n    }\n    return result;\n}\n\nmodule.exports = { add, multiply, isEven, capitalize, range };\n",
        "is_test": false
      },
      {
        "path": "test_utils.js",
        "content": "// Tests for utility functions\n\nconst { add, multiply, isEven, capitalize, range } = require('./utils');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_add() {\n    assertEquals(add(2, 3), 5, \"add(2, 3)\");\n    assertEquals(add(-1, 1), 0, \"add(-1, 1)\");\n    console.log(\"\u2713 test_add passed\");\n}\n\nfunction test_multiply() {\n    assertEquals(multiply(4, 5), 20, \"multiply(4, 5)\");\n    assertEquals(multiply(-2, 3), -6, \"multiply(-2, 3)\");\n    console.log(\"\u2713 test_multiply passed\");\n}\n\nfunction test_isEven() {\n    assertEquals(isEven(4), true, \"isEven(4)\");\n    assertEquals(isEven(5), false, \"isEven(5)\");\n    console.log(\"\u2713 test_isEven passed\");\n}\n\nfunction test_capitalize() {\n    assertEquals(capitalize(\"hello\"), \"Hello\", \"capitalize('hello')\");\n    assertEquals(capitalize(\"world\"), \"World\", \"capitalize('world')\");\n    console.log(\"\u2713 test_capitalize passed\");\n}\n\nfunction test_range() {\n    assertEquals(range(1, 5), [1, 2, 3, 4, 5], \"range(1, 5)\");\n    assertEquals(range(0, 0), [0], \"range(0, 0)\");\n    console.log(\"\u2713 test_range passed\");\n}\n\n// Run all tests\ntry {\n    test_add();\n    test_multiply();\n    test_isEven();\n    test_capitalize();\n    test_range();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 450 Oct 30 10:00 utils.js",
      "-rw-r--r-- 1 user user 1486 Oct 30 10:00 test_utils.js",
      "$ node test_utils.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_utils.js",
        "description": "Tests must run successfully (exit code 0)"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3",
        "Missing opening brace on line 7"
      ],
      "scenario_type": "utils"
    }
  },
  {
    "id": "prompt_000674",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Reorganize project structure.\n\nRequired operations:\n1. mkdir lib (create directory)\n2. cp utils.py lib/utils.py (copy file)\n3. sed -i 's/from utils/from lib.utils/g' main.py (update import)\n4. touch lib/__init__.py (make it a package)\n\nThen verify:\n5. ls lib/\n6. cat main.py | grep import",
    "files": [
      {
        "path": "utils.py",
        "content": "def utility_function():\n    return \"util\"\n",
        "is_test": false
      },
      {
        "path": "main.py",
        "content": "from utils import utility_function\n\ndef main():\n    print(utility_function())\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls",
      "tree ."
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "execution",
        "target": "main.py",
        "description": "Code should run"
      }
    ],
    "metadata": {
      "scenario_type": "file_ops",
      "command_focus": "cp,mv,mkdir"
    }
  },
  {
    "id": "prompt_000784",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000918",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000105",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000047",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000478",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000955",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Use git to track changes.\n\nWorkflow:\n1. git init (initialize repo)\n2. git add feature.py (stage file)\n3. git commit -m \"Initial commit\" (commit)\n4. sed -i 's/v1/v2/g' feature.py (make change)\n5. git diff (see changes)\n6. git add feature.py (stage changes)\n7. git commit -m \"Update to v2\"\n8. git log --oneline (view history)",
    "files": [
      {
        "path": "feature.py",
        "content": "def feature():\n    return \"v1\"  # Update to v2\n",
        "is_test": false
      }
    ],
    "cli_history": [],
    "expected_commands": 10,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "feature.py",
        "description": "Version updated"
      }
    ],
    "metadata": {
      "scenario_type": "git",
      "command_focus": "git"
    }
  },
  {
    "id": "prompt_000089",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000608",
    "difficulty": "medium",
    "language": "python",
    "task_description": "The python project has failing tests. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b)\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ndef subtract(a, b):\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 431 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing colon on line 3"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000703",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000045",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Fix log analyzer using piping commands.\n\nAnalyze logs with pipes:\n1. cat server.log | grep ERROR (see errors)\n2. cat server.log | grep ERROR | wc -l (count errors)\n3. cat server.log | cut -d' ' -f4 | sort | uniq (unique levels)\n4. grep ERROR server.log | cut -d' ' -f1-2 (error timestamps)\n\nFix the code:\nsed -i 's/count += 1/if \"ERROR\" in line:\\n                count += 1/g' analyzer.py",
    "files": [
      {
        "path": "server.log",
        "content": "2024-10-30 10:00:00 INFO Server started\n2024-10-30 10:00:01 INFO Connected to database\n2024-10-30 10:00:05 ERROR Failed to load config\n2024-10-30 10:00:10 WARNING Retry attempt 1\n2024-10-30 10:00:15 ERROR Connection timeout\n2024-10-30 10:00:20 INFO Request processed\n2024-10-30 10:00:25 ERROR Database query failed\n",
        "is_test": false
      },
      {
        "path": "analyzer.py",
        "content": "\"\"\"Log analyzer with bug.\"\"\"\n\ndef count_errors(filename):\n    # BUG: Counts all lines, not just errors\n    count = 0\n    with open(filename) as f:\n        for line in f:\n            count += 1  # Should filter for ERROR\n    return count\n",
        "is_test": false
      },
      {
        "path": "test_analyzer.py",
        "content": "from analyzer import count_errors\n\ndef test_count():\n    result = count_errors('server.log')\n    assert result == 3, f\"Expected 3 errors, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "head server.log"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_analyzer.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "piping",
      "command_focus": "pipes"
    }
  },
  {
    "id": "prompt_000318",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Fix the broken python code. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers):\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n > 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 == 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 779 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000004",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000118",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000534",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Fix the broken python code. The issue is straightforward - locate the problem and fix it. Files: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b):\n    \"\"\"Add two numbers.\"\"\"\n    return a - b\n\ndef subtract(a, b):\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls",
      "calculator.py test_calculator.py"
    ],
    "expected_commands": 3,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong arithmetic operator on line 5"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000730",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "The python project has failing tests. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: string_utils.py, test_string_utils.py",
    "files": [
      {
        "path": "string_utils.py",
        "content": "\"\"\"String utility functions.\"\"\"\n\ndef reverse_string(s)\n    \"\"\"Reverse a string.\"\"\"\n    return s[::-1]\n\ndef is_palindrome(s):\n    \"\"\"Check if string is a palindrome.\"\"\"\n    cleaned = s.lower().replace(\" \", \"\")\n    return cleaned != cleaned[::-1]\n\ndef count_vowels(s):\n    \"\"\"Count vowels in a string.\"\"\"\n    vowels = \"aeiouAEIOU\"\n    return sum(1 for char in s if char in vowels)\n\ndef capitalize_words(s):\n    \"\"\"Capitalize first letter of each word.\"\"\"\n    return \" \".join(word.capitalize() for word in s.split())\n\ndef remove_whitespace(s):\n    \"\"\"Remove all whitespace from string.\"\"\"\n    return \"\".join(s.split())\n",
        "is_test": false
      },
      {
        "path": "test_string_utils.py",
        "content": "\"\"\"Tests for string utilities.\"\"\"\n\nfrom string_utils import reverse_string, is_palindrome, count_vowels, capitalize_words, remove_whitespace\n\ndef test_reverse_string():\n    assert reverse_string(\"hello\") == \"olleh\"\n    assert reverse_string(\"\") == \"\"\n    assert reverse_string(\"a\") == \"a\"\n\ndef test_is_palindrome():\n    assert is_palindrome(\"racecar\") == True\n    assert is_palindrome(\"hello\") == False\n    assert is_palindrome(\"A man a plan a canal Panama\") == True\n\ndef test_count_vowels():\n    assert count_vowels(\"hello\") == 2\n    assert count_vowels(\"AEIOU\") == 5\n    assert count_vowels(\"xyz\") == 0\n\ndef test_capitalize_words():\n    assert capitalize_words(\"hello world\") == \"Hello World\"\n    assert capitalize_words(\"python programming\") == \"Python Programming\"\n\ndef test_remove_whitespace():\n    assert remove_whitespace(\"hello world\") == \"helloworld\"\n    assert remove_whitespace(\"  a  b  c  \") == \"abc\"\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 616 Oct 30 10:00 string_utils.py",
      "-rw-r--r-- 1 user user 913 Oct 30 10:00 test_string_utils.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_string_utils.py",
        "description": "All string utility tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing colon on line 3",
        "Wrong comparison operator on line 10"
      ],
      "scenario_type": "string_utils"
    }
  },
  {
    "id": "prompt_000396",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000470",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Fix the broken python code. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b)\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ndef subtract(a, b):\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b != 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 431 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 17",
        "Missing colon on line 3"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000037",
    "difficulty": "medium",
    "language": "javascript",
    "task_description": "The code has issues that prevent it from working correctly. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: utils.js, test_utils.js",
    "files": [
      {
        "path": "utils.js",
        "content": "// Utility functions\n\nfunction add(a, b) \n    return a + b;\n}\n\nfunction multiply(a, b) {\n    return a * b;\n}\n\nfunction isEven(n) {\n    return n % 2 !== 0;\n}\n\nfunction capitalize(str) {\n    return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\nfunction range(start, end) {\n    const result = [];\n    for (let i = start; i <= end; i++) {\n        result.push(i);\n    }\n    return result;\n}\n\nmodule.exports = { add, multiply, isEven, capitalize, range };\n",
        "is_test": false
      },
      {
        "path": "test_utils.js",
        "content": "// Tests for utility functions\n\nconst { add, multiply, isEven, capitalize, range } = require('./utils');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_add() {\n    assertEquals(add(2, 3), 5, \"add(2, 3)\");\n    assertEquals(add(-1, 1), 0, \"add(-1, 1)\");\n    console.log(\"\u2713 test_add passed\");\n}\n\nfunction test_multiply() {\n    assertEquals(multiply(4, 5), 20, \"multiply(4, 5)\");\n    assertEquals(multiply(-2, 3), -6, \"multiply(-2, 3)\");\n    console.log(\"\u2713 test_multiply passed\");\n}\n\nfunction test_isEven() {\n    assertEquals(isEven(4), true, \"isEven(4)\");\n    assertEquals(isEven(5), false, \"isEven(5)\");\n    console.log(\"\u2713 test_isEven passed\");\n}\n\nfunction test_capitalize() {\n    assertEquals(capitalize(\"hello\"), \"Hello\", \"capitalize('hello')\");\n    assertEquals(capitalize(\"world\"), \"World\", \"capitalize('world')\");\n    console.log(\"\u2713 test_capitalize passed\");\n}\n\nfunction test_range() {\n    assertEquals(range(1, 5), [1, 2, 3, 4, 5], \"range(1, 5)\");\n    assertEquals(range(0, 0), [0], \"range(0, 0)\");\n    console.log(\"\u2713 test_range passed\");\n}\n\n// Run all tests\ntry {\n    test_add();\n    test_multiply();\n    test_isEven();\n    test_capitalize();\n    test_range();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 451 Oct 30 10:00 utils.js",
      "-rw-r--r-- 1 user user 1486 Oct 30 10:00 test_utils.js"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_utils.js",
        "description": "Tests must run successfully (exit code 0)"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3",
        "Wrong comparison operator on line 12"
      ],
      "scenario_type": "utils"
    }
  },
  {
    "id": "prompt_000952",
    "difficulty": "very_hard",
    "language": "javascript",
    "task_description": "The javascript project has failing tests. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: validators.js, test_validators.js",
    "files": [
      {
        "path": "validators.js",
        "content": "// Validation functions\n\nfunction isValidEmail(email) {\n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n}\n\nfunction isValidPhone(phone) {\n    const regex = /^\\d{3}-\\d{3}-\\d{4}$/;\n    return regex.test(phone);\n}\n\nfunction isValidPassword(password) {\n    return password.length >= 8;\n}\n\nfunction isValidUsername(username) {\n    const regex = /^[a-zA-Z0-9_]{3,20}$/;\n    return regex.test(username);\n}\n\nmodule.exports = { isValidEmail, isValidPhone, isValidPassword, isValidUsername };\n",
        "is_test": false
      },
      {
        "path": "test_validators.js",
        "content": "// Tests for validators\n\nconst { isValidEmail, isValidPhone, isValidPassword, isValidUsername } = require('./validators');\n\nfunction assertEquals(actual, expected, message) {\n    if (actual !== expected) {\n        throw new Error(`${message}: expected ${expected}, got ${actual}`);\n    }\n}\n\nfunction test_isValidEmail() {\n    assertEquals(isValidEmail(\"user@example.com\"), true, \"valid email\");\n    assertEquals(isValidEmail(\"invalid\"), false, \"invalid email\");\n    console.log(\"\u2713 test_isValidEmail passed\");\n}\n\nfunction test_isValidPhone() {\n    assertEquals(isValidPhone(\"123-456-7890\"), true, \"valid phone\");\n    assertEquals(isValidPhone(\"1234567890\"), false, \"invalid phone\");\n    console.log(\"\u2713 test_isValidPhone passed\");\n}\n\nfunction test_isValidPassword() {\n    assertEquals(isValidPassword(\"password123\"), true, \"valid password\");\n    assertEquals(isValidPassword(\"short\"), false, \"invalid password\");\n    console.log(\"\u2713 test_isValidPassword passed\");\n}\n\nfunction test_isValidUsername() {\n    assertEquals(isValidUsername(\"user_123\"), true, \"valid username\");\n    assertEquals(isValidUsername(\"ab\"), false, \"too short username\");\n    console.log(\"\u2713 test_isValidUsername passed\");\n}\n\n// Run all tests\ntry {\n    test_isValidEmail();\n    test_isValidPhone();\n    test_isValidPassword();\n    test_isValidUsername();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 513 Oct 30 10:00 validators.js",
      "-rw-r--r-- 1 user user 1442 Oct 30 10:00 test_validators.js",
      "$ node test_validators.js",
      "Test failed: ..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_validators.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [],
      "scenario_type": "validators"
    }
  },
  {
    "id": "prompt_000210",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000135",
    "difficulty": "medium",
    "language": "python",
    "task_description": "There's a bug in the python code that needs fixing. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers):\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n > 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 == 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 779 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000692",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Fix the CSV processor that fails on the header line.\n\nExplore the data first:\n1. cat data.csv\n2. head -n 1 data.csv (see header)\n3. tail -n +2 data.csv (see data without header)\n4. cut -d',' -f3 data.csv (extract scores)\n5. awk -F',' 'NR>1 {print $3}' data.csv (scores without header)\n\nFix by skipping header:\nsed -i '/for line in f:/a\\        next(f)  # Skip header' processor.py",
    "files": [
      {
        "path": "data.csv",
        "content": "name,age,score\nAlice,25,85\nBob,30,92\nCharlie,22,78\nDavid,35,95\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "\"\"\"Process CSV data.\"\"\"\n\ndef process_data(filename):\n    # BUG: Doesn't handle header correctly\n    total = 0\n    with open(filename) as f:\n        for line in f:\n            parts = line.strip().split(',')\n            total += int(parts[2])  # Will fail on header\n    return total\n",
        "is_test": false
      },
      {
        "path": "test_processor.py",
        "content": "from processor import process_data\n\ndef test_process():\n    result = process_data('data.csv')\n    assert result == 350, f\"Expected 350, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat data.csv | head -3"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_processor.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "awk_cut",
      "command_focus": "awk,cut"
    }
  },
  {
    "id": "prompt_000528",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000100",
    "difficulty": "very_hard",
    "language": "javascript",
    "task_description": "Use grep to find and fix the bug.\n            \nRequired commands:\n1. grep -n \"function\" main.js\n2. grep \"helperOne\" main.js\n3. grep \"Expected\" test_main.js\n4. Fix with sed: sed -i 's/x + 1/x * 2/g' main.js",
    "files": [
      {
        "path": "main.js",
        "content": "// Multi-function utility module\n\nfunction helperOne(x) {\n    return x + 1;  // BUG: Should multiply by 2\n}\n\nfunction helperTwo(x) {\n    return x * 2;\n}\n\nfunction processData(items) {\n    return items.map(helperOne);\n}\n\nmodule.exports = { processData, helperOne, helperTwo };\n",
        "is_test": false
      },
      {
        "path": "test_main.js",
        "content": "const { processData } = require('./main');\n\nfunction test_processData() {\n    const result = processData([1, 2, 3]);\n    const expected = [2, 4, 6];\n    if (JSON.stringify(result) !== JSON.stringify(expected)) {\n        throw new Error(`Expected ${expected}, got ${result}`);\n    }\n    console.log(\"\u2713 test_processData passed\");\n}\n\ntest_processData();\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat main.js"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_main.js",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "grep_intensive",
      "command_focus": "grep"
    }
  },
  {
    "id": "prompt_000787",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000146",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Fix multiple bugs using sed commands.\n\nRequired:\n1. sed -i 's/a - b/a + b/g' calculator.py\n2. sed -i 's/x + y/x * y/g' calculator.py\n3. sed -i '/DEBUG/d' calculator.py (remove debug line)\n4. Add zero check: sed -i '/return a \\/ b/i\\    if b == 0: raise ValueError(\"Division by zero\")' calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Module with multiple bugs.\"\"\"\n\ndef calculate(a, b):\n    # BUG 1: Wrong operator\n    result = a - b  # Should be a + b\n    return result\n\ndef multiply(x, y):\n    # BUG 2: Wrong operator\n    return x + y  # Should be x * y\n\ndef divide(a, b):\n    # BUG 3: Missing check\n    return a / b  # Should check b != 0\n\n# DEBUG CODE TO REMOVE\nprint(\"DEBUG: Loading module\")\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "import pytest\nfrom calculator import calculate, multiply, divide\n\ndef test_calculate():\n    assert calculate(5, 3) == 8\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n\ndef test_divide():\n    assert divide(10, 2) == 5\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000335",
    "difficulty": "very_hard",
    "language": "javascript",
    "task_description": "Fix bugs with multiple sed commands.\n\nUse:\n1. sed -i 's/a - b/a + b/g' calculator.js\n2. sed -i 's/x + y/x \\* y/g' calculator.js\n3. sed -i '/DEBUG/d' calculator.js",
    "files": [
      {
        "path": "calculator.js",
        "content": "// Module with bugs\n\nfunction calculate(a, b) {\n    // BUG: Wrong operator\n    return a - b;  // Should be a + b\n}\n\nfunction multiply(x, y) {\n    // BUG: Wrong operator\n    return x + y;  // Should be x * y\n}\n\n// DEBUG\nconsole.log(\"DEBUG: Loading\");\n\nmodule.exports = { calculate, multiply };\n",
        "is_test": false
      },
      {
        "path": "test_calculator.js",
        "content": "const { calculate, multiply } = require('./calculator');\n\nif (calculate(5, 3) !== 8) throw new Error(\"calculate failed\");\nif (multiply(4, 5) !== 20) throw new Error(\"multiply failed\");\nconsole.log(\"\u2713 All tests passed\");\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.js",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000794",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "Fix the broken javascript code. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: array_ops.js, test_array_ops.js",
    "files": [
      {
        "path": "array_ops.js",
        "content": "// Array operation functions\n\nfunction sum(arr) \n    return arr.reduce((a, b) => a + b, 0);\n}\n\nfunction findMax(arr) {\n    if (arr.length !!= 0) return null;\n    return Math.max(...arr);\n}\n\nfunction removeDuplicates(arr) {\n    return [...new Set(arr)];\n}\n\nfunction flatten(arr) {\n    return arr.flat();\n}\n\nfunction chunk(arr, size) {\n    const result = [];\n    for (let i = 0; i < arr.length; i += size) {\n        result.push(arr.slice(i, i + size));\n    }\n    return result;\n}\n\nmodule.exports = { sum, findMax, removeDuplicates, flatten, chunk };\n",
        "is_test": false
      },
      {
        "path": "test_array_ops.js",
        "content": "// Tests for array operations\n\nconst { sum, findMax, removeDuplicates, flatten, chunk } = require('./array_ops');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_sum() {\n    assertEquals(sum([1, 2, 3, 4, 5]), 15, \"sum([1, 2, 3, 4, 5])\");\n    assertEquals(sum([]), 0, \"sum([])\");\n    console.log(\"\u2713 test_sum passed\");\n}\n\nfunction test_findMax() {\n    assertEquals(findMax([1, 5, 3, 9, 2]), 9, \"findMax([1, 5, 3, 9, 2])\");\n    assertEquals(findMax([]), null, \"findMax([])\");\n    console.log(\"\u2713 test_findMax passed\");\n}\n\nfunction test_removeDuplicates() {\n    assertEquals(removeDuplicates([1, 2, 2, 3, 1, 4]), [1, 2, 3, 4], \"removeDuplicates\");\n    console.log(\"\u2713 test_removeDuplicates passed\");\n}\n\nfunction test_flatten() {\n    assertEquals(flatten([[1, 2], [3, 4], [5]]), [1, 2, 3, 4, 5], \"flatten\");\n    console.log(\"\u2713 test_flatten passed\");\n}\n\nfunction test_chunk() {\n    assertEquals(chunk([1, 2, 3, 4, 5], 2), [[1, 2], [3, 4], [5]], \"chunk\");\n    console.log(\"\u2713 test_chunk passed\");\n}\n\n// Run all tests\ntry {\n    test_sum();\n    test_findMax();\n    test_removeDuplicates();\n    test_flatten();\n    test_chunk();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 548 Oct 30 10:00 array_ops.js",
      "-rw-r--r-- 1 user user 1435 Oct 30 10:00 test_array_ops.js",
      "$ node test_array_ops.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_array_ops.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 8",
        "Wrong comparison operator on line 8",
        "Missing opening brace on line 3"
      ],
      "scenario_type": "array_ops"
    }
  },
  {
    "id": "prompt_000317",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "The code has issues that prevent it from working correctly. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: string_utils.py, test_string_utils.py",
    "files": [
      {
        "path": "string_utils.py",
        "content": "\"\"\"String utility functions.\"\"\"\n\ndef reverse_string(s):\n    \"\"\"Reverse a string.\"\"\"\n    return s[::-1]\n\ndef is_palindrome(s):\n    \"\"\"Check if string is a palindrome.\"\"\"\n    cleaned = s.lower().replace(\" \", \"\")\n    return cleaned != cleaned[::-1]\n\ndef count_vowels(s):\n    \"\"\"Count vowels in a string.\"\"\"\n    vowels = \"aeiouAEIOU\"\n    return sum(1 for char in s if char in vowels)\n\ndef capitalize_words(s):\n    \"\"\"Capitalize first letter of each word.\"\"\"\n    return \" \".join(word.capitalize() for word in s.split())\n\ndef remove_whitespace(s):\n    \"\"\"Remove all whitespace from string.\"\"\"\n    return \"\".join(s.split())\n",
        "is_test": false
      },
      {
        "path": "test_string_utils.py",
        "content": "\"\"\"Tests for string utilities.\"\"\"\n\nfrom string_utils import reverse_string, is_palindrome, count_vowels, capitalize_words, remove_whitespace\n\ndef test_reverse_string():\n    assert reverse_string(\"hello\") == \"olleh\"\n    assert reverse_string(\"\") == \"\"\n    assert reverse_string(\"a\") == \"a\"\n\ndef test_is_palindrome():\n    assert is_palindrome(\"racecar\") == True\n    assert is_palindrome(\"hello\") == False\n    assert is_palindrome(\"A man a plan a canal Panama\") == True\n\ndef test_count_vowels():\n    assert count_vowels(\"hello\") == 2\n    assert count_vowels(\"AEIOU\") == 5\n    assert count_vowels(\"xyz\") == 0\n\ndef test_capitalize_words():\n    assert capitalize_words(\"hello world\") == \"Hello World\"\n    assert capitalize_words(\"python programming\") == \"Python Programming\"\n\ndef test_remove_whitespace():\n    assert remove_whitespace(\"hello world\") == \"helloworld\"\n    assert remove_whitespace(\"  a  b  c  \") == \"abc\"\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 617 Oct 30 10:00 string_utils.py",
      "-rw-r--r-- 1 user user 913 Oct 30 10:00 test_string_utils.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_string_utils.py",
        "description": "All string utility tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 10"
      ],
      "scenario_type": "string_utils"
    }
  },
  {
    "id": "prompt_000536",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000750",
    "difficulty": "very_hard",
    "language": "javascript",
    "task_description": "Fix bugs with multiple sed commands.\n\nUse:\n1. sed -i 's/a - b/a + b/g' calculator.js\n2. sed -i 's/x + y/x \\* y/g' calculator.js\n3. sed -i '/DEBUG/d' calculator.js",
    "files": [
      {
        "path": "calculator.js",
        "content": "// Module with bugs\n\nfunction calculate(a, b) {\n    // BUG: Wrong operator\n    return a - b;  // Should be a + b\n}\n\nfunction multiply(x, y) {\n    // BUG: Wrong operator\n    return x + y;  // Should be x * y\n}\n\n// DEBUG\nconsole.log(\"DEBUG: Loading\");\n\nmodule.exports = { calculate, multiply };\n",
        "is_test": false
      },
      {
        "path": "test_calculator.js",
        "content": "const { calculate, multiply } = require('./calculator');\n\nif (calculate(5, 3) !== 8) throw new Error(\"calculate failed\");\nif (multiply(4, 5) !== 20) throw new Error(\"multiply failed\");\nconsole.log(\"\u2713 All tests passed\");\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.js",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000495",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Fix log analyzer using piping commands.\n\nAnalyze logs with pipes:\n1. cat server.log | grep ERROR (see errors)\n2. cat server.log | grep ERROR | wc -l (count errors)\n3. cat server.log | cut -d' ' -f4 | sort | uniq (unique levels)\n4. grep ERROR server.log | cut -d' ' -f1-2 (error timestamps)\n\nFix the code:\nsed -i 's/count += 1/if \"ERROR\" in line:\\n                count += 1/g' analyzer.py",
    "files": [
      {
        "path": "server.log",
        "content": "2024-10-30 10:00:00 INFO Server started\n2024-10-30 10:00:01 INFO Connected to database\n2024-10-30 10:00:05 ERROR Failed to load config\n2024-10-30 10:00:10 WARNING Retry attempt 1\n2024-10-30 10:00:15 ERROR Connection timeout\n2024-10-30 10:00:20 INFO Request processed\n2024-10-30 10:00:25 ERROR Database query failed\n",
        "is_test": false
      },
      {
        "path": "analyzer.py",
        "content": "\"\"\"Log analyzer with bug.\"\"\"\n\ndef count_errors(filename):\n    # BUG: Counts all lines, not just errors\n    count = 0\n    with open(filename) as f:\n        for line in f:\n            count += 1  # Should filter for ERROR\n    return count\n",
        "is_test": false
      },
      {
        "path": "test_analyzer.py",
        "content": "from analyzer import count_errors\n\ndef test_count():\n    result = count_errors('server.log')\n    assert result == 3, f\"Expected 3 errors, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "head server.log"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_analyzer.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "piping",
      "command_focus": "pipes"
    }
  },
  {
    "id": "prompt_000348",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Use git to track changes.\n\nWorkflow:\n1. git init (initialize repo)\n2. git add feature.py (stage file)\n3. git commit -m \"Initial commit\" (commit)\n4. sed -i 's/v1/v2/g' feature.py (make change)\n5. git diff (see changes)\n6. git add feature.py (stage changes)\n7. git commit -m \"Update to v2\"\n8. git log --oneline (view history)",
    "files": [
      {
        "path": "feature.py",
        "content": "def feature():\n    return \"v1\"  # Update to v2\n",
        "is_test": false
      }
    ],
    "cli_history": [],
    "expected_commands": 10,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "feature.py",
        "description": "Version updated"
      }
    ],
    "metadata": {
      "scenario_type": "git",
      "command_focus": "git"
    }
  },
  {
    "id": "prompt_000194",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000157",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix the broken python code. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b)\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ndef subtract(a, b)\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b)\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 429 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing colon on line 3",
        "Missing colon on line 7",
        "Missing colon on line 11"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000512",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000494",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000905",
    "difficulty": "medium",
    "language": "javascript",
    "task_description": "There's a bug in the javascript code that needs fixing. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: validators.js, test_validators.js",
    "files": [
      {
        "path": "validators.js",
        "content": "// Validation functions\n\nfunction isValidEmail(email) \n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n}\n\nfunction isValidPhone(phone) {\n    const regex = /^\\d{3}-\\d{3}-\\d{4}$/;\n    return regex.test(phone);\n}\n\nfunction isValidPassword(password) {\n    return password.length >= 8;\n}\n\nfunction isValidUsername(username) {\n    const regex = /^[a-zA-Z0-9_]{3,20}$/;\n    return regex.test(username);\n}\n\nmodule.exports = { isValidEmail, isValidPhone, isValidPassword, isValidUsername };\n",
        "is_test": false
      },
      {
        "path": "test_validators.js",
        "content": "// Tests for validators\n\nconst { isValidEmail, isValidPhone, isValidPassword, isValidUsername } = require('./validators');\n\nfunction assertEquals(actual, expected, message) {\n    if (actual !== expected) {\n        throw new Error(`${message}: expected ${expected}, got ${actual}`);\n    }\n}\n\nfunction test_isValidEmail() {\n    assertEquals(isValidEmail(\"user@example.com\"), true, \"valid email\");\n    assertEquals(isValidEmail(\"invalid\"), false, \"invalid email\");\n    console.log(\"\u2713 test_isValidEmail passed\");\n}\n\nfunction test_isValidPhone() {\n    assertEquals(isValidPhone(\"123-456-7890\"), true, \"valid phone\");\n    assertEquals(isValidPhone(\"1234567890\"), false, \"invalid phone\");\n    console.log(\"\u2713 test_isValidPhone passed\");\n}\n\nfunction test_isValidPassword() {\n    assertEquals(isValidPassword(\"password123\"), true, \"valid password\");\n    assertEquals(isValidPassword(\"short\"), false, \"invalid password\");\n    console.log(\"\u2713 test_isValidPassword passed\");\n}\n\nfunction test_isValidUsername() {\n    assertEquals(isValidUsername(\"user_123\"), true, \"valid username\");\n    assertEquals(isValidUsername(\"ab\"), false, \"too short username\");\n    console.log(\"\u2713 test_isValidUsername passed\");\n}\n\n// Run all tests\ntry {\n    test_isValidEmail();\n    test_isValidPhone();\n    test_isValidPassword();\n    test_isValidUsername();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 512 Oct 30 10:00 validators.js",
      "-rw-r--r-- 1 user user 1442 Oct 30 10:00 test_validators.js"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_validators.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3"
      ],
      "scenario_type": "validators"
    }
  },
  {
    "id": "prompt_000025",
    "difficulty": "medium",
    "language": "javascript",
    "task_description": "There's a bug in the javascript code that needs fixing. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: validators.js, test_validators.js",
    "files": [
      {
        "path": "validators.js",
        "content": "// Validation functions\n\nfunction isValidEmail(email) {\n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n}\n\nfunction isValidPhone(phone) {\n    const regex = /^\\d{3}-\\d{3}-\\d{4}$/;\n    return regex.test(phone);\n}\n\nfunction isValidPassword(password) {\n    return password.length >= 8;\n}\n\nfunction isValidUsername(username) {\n    const regex = /^[a-zA-Z0-9_]{3,20}$/;\n    return regex.test(username);\n}\n\nmodule.exports = { isValidEmail, isValidPhone, isValidPassword, isValidUsername };\n",
        "is_test": false
      },
      {
        "path": "test_validators.js",
        "content": "// Tests for validators\n\nconst { isValidEmail, isValidPhone, isValidPassword, isValidUsername } = require('./validators');\n\nfunction assertEquals(actual, expected, message) {\n    if (actual !== expected) {\n        throw new Error(`${message}: expected ${expected}, got ${actual}`);\n    }\n}\n\nfunction test_isValidEmail() {\n    assertEquals(isValidEmail(\"user@example.com\"), true, \"valid email\");\n    assertEquals(isValidEmail(\"invalid\"), false, \"invalid email\");\n    console.log(\"\u2713 test_isValidEmail passed\");\n}\n\nfunction test_isValidPhone() {\n    assertEquals(isValidPhone(\"123-456-7890\"), true, \"valid phone\");\n    assertEquals(isValidPhone(\"1234567890\"), false, \"invalid phone\");\n    console.log(\"\u2713 test_isValidPhone passed\");\n}\n\nfunction test_isValidPassword() {\n    assertEquals(isValidPassword(\"password123\"), true, \"valid password\");\n    assertEquals(isValidPassword(\"short\"), false, \"invalid password\");\n    console.log(\"\u2713 test_isValidPassword passed\");\n}\n\nfunction test_isValidUsername() {\n    assertEquals(isValidUsername(\"user_123\"), true, \"valid username\");\n    assertEquals(isValidUsername(\"ab\"), false, \"too short username\");\n    console.log(\"\u2713 test_isValidUsername passed\");\n}\n\n// Run all tests\ntry {\n    test_isValidEmail();\n    test_isValidPhone();\n    test_isValidPassword();\n    test_isValidUsername();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 513 Oct 30 10:00 validators.js",
      "-rw-r--r-- 1 user user 1442 Oct 30 10:00 test_validators.js"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_validators.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [],
      "scenario_type": "validators"
    }
  },
  {
    "id": "prompt_000962",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix log analyzer using piping commands.\n\nAnalyze logs with pipes:\n1. cat server.log | grep ERROR (see errors)\n2. cat server.log | grep ERROR | wc -l (count errors)\n3. cat server.log | cut -d' ' -f4 | sort | uniq (unique levels)\n4. grep ERROR server.log | cut -d' ' -f1-2 (error timestamps)\n\nFix the code:\nsed -i 's/count += 1/if \"ERROR\" in line:\\n                count += 1/g' analyzer.py",
    "files": [
      {
        "path": "server.log",
        "content": "2024-10-30 10:00:00 INFO Server started\n2024-10-30 10:00:01 INFO Connected to database\n2024-10-30 10:00:05 ERROR Failed to load config\n2024-10-30 10:00:10 WARNING Retry attempt 1\n2024-10-30 10:00:15 ERROR Connection timeout\n2024-10-30 10:00:20 INFO Request processed\n2024-10-30 10:00:25 ERROR Database query failed\n",
        "is_test": false
      },
      {
        "path": "analyzer.py",
        "content": "\"\"\"Log analyzer with bug.\"\"\"\n\ndef count_errors(filename):\n    # BUG: Counts all lines, not just errors\n    count = 0\n    with open(filename) as f:\n        for line in f:\n            count += 1  # Should filter for ERROR\n    return count\n",
        "is_test": false
      },
      {
        "path": "test_analyzer.py",
        "content": "from analyzer import count_errors\n\ndef test_count():\n    result = count_errors('server.log')\n    assert result == 3, f\"Expected 3 errors, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "head server.log"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_analyzer.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "piping",
      "command_focus": "pipes"
    }
  },
  {
    "id": "prompt_000454",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Use git to track changes.\n\nWorkflow:\n1. git init (initialize repo)\n2. git add feature.py (stage file)\n3. git commit -m \"Initial commit\" (commit)\n4. sed -i 's/v1/v2/g' feature.py (make change)\n5. git diff (see changes)\n6. git add feature.py (stage changes)\n7. git commit -m \"Update to v2\"\n8. git log --oneline (view history)",
    "files": [
      {
        "path": "feature.py",
        "content": "def feature():\n    return \"v1\"  # Update to v2\n",
        "is_test": false
      }
    ],
    "cli_history": [],
    "expected_commands": 10,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "feature.py",
        "description": "Version updated"
      }
    ],
    "metadata": {
      "scenario_type": "git",
      "command_focus": "git"
    }
  },
  {
    "id": "prompt_000094",
    "difficulty": "hard",
    "language": "python",
    "task_description": "There's a bug in the python code that needs fixing. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b):\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ndef subtract(a, b):\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b != 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 432 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 17"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000970",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000796",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix the CSV processor that fails on the header line.\n\nExplore the data first:\n1. cat data.csv\n2. head -n 1 data.csv (see header)\n3. tail -n +2 data.csv (see data without header)\n4. cut -d',' -f3 data.csv (extract scores)\n5. awk -F',' 'NR>1 {print $3}' data.csv (scores without header)\n\nFix by skipping header:\nsed -i '/for line in f:/a\\        next(f)  # Skip header' processor.py",
    "files": [
      {
        "path": "data.csv",
        "content": "name,age,score\nAlice,25,85\nBob,30,92\nCharlie,22,78\nDavid,35,95\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "\"\"\"Process CSV data.\"\"\"\n\ndef process_data(filename):\n    # BUG: Doesn't handle header correctly\n    total = 0\n    with open(filename) as f:\n        for line in f:\n            parts = line.strip().split(',')\n            total += int(parts[2])  # Will fail on header\n    return total\n",
        "is_test": false
      },
      {
        "path": "test_processor.py",
        "content": "from processor import process_data\n\ndef test_process():\n    result = process_data('data.csv')\n    assert result == 350, f\"Expected 350, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat data.csv | head -3"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_processor.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "awk_cut",
      "command_focus": "awk,cut"
    }
  },
  {
    "id": "prompt_000038",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix multiple bugs using sed commands.\n\nRequired:\n1. sed -i 's/a - b/a + b/g' calculator.py\n2. sed -i 's/x + y/x * y/g' calculator.py\n3. sed -i '/DEBUG/d' calculator.py (remove debug line)\n4. Add zero check: sed -i '/return a \\/ b/i\\    if b == 0: raise ValueError(\"Division by zero\")' calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Module with multiple bugs.\"\"\"\n\ndef calculate(a, b):\n    # BUG 1: Wrong operator\n    result = a - b  # Should be a + b\n    return result\n\ndef multiply(x, y):\n    # BUG 2: Wrong operator\n    return x + y  # Should be x * y\n\ndef divide(a, b):\n    # BUG 3: Missing check\n    return a / b  # Should check b != 0\n\n# DEBUG CODE TO REMOVE\nprint(\"DEBUG: Loading module\")\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "import pytest\nfrom calculator import calculate, multiply, divide\n\ndef test_calculate():\n    assert calculate(5, 3) == 8\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n\ndef test_divide():\n    assert divide(10, 2) == 5\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000803",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000383",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000114",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Reorganize project structure.\n\nRequired operations:\n1. mkdir lib (create directory)\n2. cp utils.py lib/utils.py (copy file)\n3. sed -i 's/from utils/from lib.utils/g' main.py (update import)\n4. touch lib/__init__.py (make it a package)\n\nThen verify:\n5. ls lib/\n6. cat main.py | grep import",
    "files": [
      {
        "path": "utils.py",
        "content": "def utility_function():\n    return \"util\"\n",
        "is_test": false
      },
      {
        "path": "main.py",
        "content": "from utils import utility_function\n\ndef main():\n    print(utility_function())\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls",
      "tree ."
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "execution",
        "target": "main.py",
        "description": "Code should run"
      }
    ],
    "metadata": {
      "scenario_type": "file_ops",
      "command_focus": "cp,mv,mkdir"
    }
  },
  {
    "id": "prompt_000947",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "There's a bug in the javascript code that needs fixing. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: utils.js, test_utils.js",
    "files": [
      {
        "path": "utils.js",
        "content": "// Utility functions\n\nfunction add(a, b) \n    return a - b;\n}\n\nfunction multiply(a, b) {\n    return a * b;\n}\n\nfunction isEven(n) {\n    return n % 2 === 0;\n}\n\nfunction capitalize(str) {\n    return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\nfunction range(start, end) {\n    const result = [];\n    for (let i = start; i <= end; i++) {\n        result.push(i);\n    }\n    return result;\n}\n\nmodule.exports = { add, multiply, isEven, capitalize, range };\n",
        "is_test": false
      },
      {
        "path": "test_utils.js",
        "content": "// Tests for utility functions\n\nconst { add, multiply, isEven, capitalize, range } = require('./utils');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_add() {\n    assertEquals(add(2, 3), 5, \"add(2, 3)\");\n    assertEquals(add(-1, 1), 0, \"add(-1, 1)\");\n    console.log(\"\u2713 test_add passed\");\n}\n\nfunction test_multiply() {\n    assertEquals(multiply(4, 5), 20, \"multiply(4, 5)\");\n    assertEquals(multiply(-2, 3), -6, \"multiply(-2, 3)\");\n    console.log(\"\u2713 test_multiply passed\");\n}\n\nfunction test_isEven() {\n    assertEquals(isEven(4), true, \"isEven(4)\");\n    assertEquals(isEven(5), false, \"isEven(5)\");\n    console.log(\"\u2713 test_isEven passed\");\n}\n\nfunction test_capitalize() {\n    assertEquals(capitalize(\"hello\"), \"Hello\", \"capitalize('hello')\");\n    assertEquals(capitalize(\"world\"), \"World\", \"capitalize('world')\");\n    console.log(\"\u2713 test_capitalize passed\");\n}\n\nfunction test_range() {\n    assertEquals(range(1, 5), [1, 2, 3, 4, 5], \"range(1, 5)\");\n    assertEquals(range(0, 0), [0], \"range(0, 0)\");\n    console.log(\"\u2713 test_range passed\");\n}\n\n// Run all tests\ntry {\n    test_add();\n    test_multiply();\n    test_isEven();\n    test_capitalize();\n    test_range();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 451 Oct 30 10:00 utils.js",
      "-rw-r--r-- 1 user user 1486 Oct 30 10:00 test_utils.js",
      "$ node test_utils.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_utils.js",
        "description": "Tests must run successfully (exit code 0)"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3",
        "Wrong arithmetic operator on line 4"
      ],
      "scenario_type": "utils"
    }
  },
  {
    "id": "prompt_000985",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Compare files and create a merged version.\n\nCommands:\n1. diff fruits1.txt fruits2.txt (see differences)\n2. diff -u fruits1.txt fruits2.txt (unified format)\n3. comm fruits1.txt fruits2.txt (common lines)\n4. cat fruits1.txt fruits2.txt | sort | uniq > merged.txt\n5. cat merged.txt (verify)",
    "files": [
      {
        "path": "fruits1.txt",
        "content": "apple\nbanana\ncherry\n",
        "is_test": false
      },
      {
        "path": "fruits2.txt",
        "content": "apple\nblueberry\ncherry\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.txt"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "merged.txt",
        "description": "Has new fruit"
      }
    ],
    "metadata": {
      "scenario_type": "comparison",
      "command_focus": "diff,comm"
    }
  },
  {
    "id": "prompt_000537",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "Fix the broken javascript code. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: validators.js, test_validators.js",
    "files": [
      {
        "path": "validators.js",
        "content": "// Validation functions\n\nfunction isValidEmail(email) \n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n}\n\nfunction isValidPhone(phone) {\n    const regex = /^\\d{3}-\\d{3}-\\d{4}$/;\n    return regex.test(phone);\n}\n\nfunction isValidPassword(password) {\n    return password.length >= 8;\n}\n\nfunction isValidUsername(username) {\n    const regex = /^[a-zA-Z0-9_]{3,20}$/;\n    return regex.test(username);\n}\n\nmodule.exports = { isValidEmail, isValidPhone, isValidPassword, isValidUsername };\n",
        "is_test": false
      },
      {
        "path": "test_validators.js",
        "content": "// Tests for validators\n\nconst { isValidEmail, isValidPhone, isValidPassword, isValidUsername } = require('./validators');\n\nfunction assertEquals(actual, expected, message) {\n    if (actual !== expected) {\n        throw new Error(`${message}: expected ${expected}, got ${actual}`);\n    }\n}\n\nfunction test_isValidEmail() {\n    assertEquals(isValidEmail(\"user@example.com\"), true, \"valid email\");\n    assertEquals(isValidEmail(\"invalid\"), false, \"invalid email\");\n    console.log(\"\u2713 test_isValidEmail passed\");\n}\n\nfunction test_isValidPhone() {\n    assertEquals(isValidPhone(\"123-456-7890\"), true, \"valid phone\");\n    assertEquals(isValidPhone(\"1234567890\"), false, \"invalid phone\");\n    console.log(\"\u2713 test_isValidPhone passed\");\n}\n\nfunction test_isValidPassword() {\n    assertEquals(isValidPassword(\"password123\"), true, \"valid password\");\n    assertEquals(isValidPassword(\"short\"), false, \"invalid password\");\n    console.log(\"\u2713 test_isValidPassword passed\");\n}\n\nfunction test_isValidUsername() {\n    assertEquals(isValidUsername(\"user_123\"), true, \"valid username\");\n    assertEquals(isValidUsername(\"ab\"), false, \"too short username\");\n    console.log(\"\u2713 test_isValidUsername passed\");\n}\n\n// Run all tests\ntry {\n    test_isValidEmail();\n    test_isValidPhone();\n    test_isValidPassword();\n    test_isValidUsername();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 512 Oct 30 10:00 validators.js",
      "-rw-r--r-- 1 user user 1442 Oct 30 10:00 test_validators.js",
      "$ node test_validators.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_validators.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3"
      ],
      "scenario_type": "validators"
    }
  },
  {
    "id": "prompt_000221",
    "difficulty": "hard",
    "language": "python",
    "task_description": "There's a bug in the python code that needs fixing. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: algorithms.py, test_algorithms.py",
    "files": [
      {
        "path": "algorithms.py",
        "content": "\"\"\"Algorithm implementations.\"\"\"\n\ndef binary_search(arr, target):\n    \"\"\"Binary search in sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] != target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1\n\ndef bubble_sort(arr):\n    \"\"\"Sort array using bubble sort.\"\"\"\n    n = len(arr)\n    for i in range(n):\n        for j in range(0, n - i - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n\ndef fibonacci(n):\n    \"\"\"Calculate nth Fibonacci number.\"\"\"\n    if n <= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fibonacci(n - 1) - fibonacci(n - 2)\n\ndef factorial(n):\n    \"\"\"Calculate factorial of n.\"\"\"\n    if n == 0 or n == 1:\n        return 1\n    return n * factorial(n - 1)\n",
        "is_test": false
      },
      {
        "path": "test_algorithms.py",
        "content": "\"\"\"Tests for algorithms.\"\"\"\n\nfrom algorithms import binary_search, bubble_sort, fibonacci, factorial\n\ndef test_binary_search():\n    assert binary_search([1, 2, 3, 4, 5], 3) == 2\n    assert binary_search([1, 2, 3, 4, 5], 6) == -1\n    assert binary_search([1], 1) == 0\n\ndef test_bubble_sort():\n    assert bubble_sort([3, 1, 4, 1, 5]) == [1, 1, 3, 4, 5]\n    assert bubble_sort([]) == []\n    assert bubble_sort([1]) == [1]\n\ndef test_fibonacci():\n    assert fibonacci(0) == 0\n    assert fibonacci(1) == 1\n    assert fibonacci(5) == 5\n    assert fibonacci(10) == 55\n\ndef test_factorial():\n    assert factorial(0) == 1\n    assert factorial(1) == 1\n    assert factorial(5) == 120\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 934 Oct 30 10:00 algorithms.py",
      "-rw-r--r-- 1 user user 672 Oct 30 10:00 test_algorithms.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_algorithms.py",
        "description": "All algorithm tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 8",
        "Wrong arithmetic operator on line 32"
      ],
      "scenario_type": "algorithms"
    }
  },
  {
    "id": "prompt_000309",
    "difficulty": "medium",
    "language": "python",
    "task_description": "The code has a bug in one of the helper functions. \n            \nUse grep to:\n1. Find all function definitions: grep -n \"def\" main.py\n2. Search for the buggy helper usage: grep -r \"helper_one\" .\n3. Check the test expectations: grep \"assert\" test_main.py\n4. Find the bug and fix it with sed\n\nThe bug is in helper_one - it adds instead of multiplies.",
    "files": [
      {
        "path": "main.py",
        "content": "\"\"\"Multi-module project with issues.\"\"\"\n\n# utils.py functions\ndef helper_one(x):\n    return x + 1  # BUG: Should multiply by 2\n\ndef helper_two(x):\n    return x * 2\n\n# Main functions\ndef process_data(items):\n    result = []\n    for item in items:\n        result.append(helper_one(item))  # Uses buggy function\n    return result\n\ndef calculate_total(values):\n    return sum(values)\n",
        "is_test": false
      },
      {
        "path": "test_main.py",
        "content": "\"\"\"Tests for the module.\"\"\"\nimport pytest\nfrom main import process_data, calculate_total\n\ndef test_process_data():\n    assert process_data([1, 2, 3]) == [2, 4, 6]\n\ndef test_calculate_total():\n    assert calculate_total([1, 2, 3]) == 6\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat main.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_main.py",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "grep_intensive",
      "command_focus": "grep"
    }
  },
  {
    "id": "prompt_000849",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "The python project has failing tests. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b)\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ndef subtract(a, b)\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 430 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing colon on line 3",
        "Missing colon on line 7"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000462",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000380",
    "difficulty": "easy",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000243",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Reorganize project structure.\n\nRequired operations:\n1. mkdir lib (create directory)\n2. cp utils.py lib/utils.py (copy file)\n3. sed -i 's/from utils/from lib.utils/g' main.py (update import)\n4. touch lib/__init__.py (make it a package)\n\nThen verify:\n5. ls lib/\n6. cat main.py | grep import",
    "files": [
      {
        "path": "utils.py",
        "content": "def utility_function():\n    return \"util\"\n",
        "is_test": false
      },
      {
        "path": "main.py",
        "content": "from utils import utility_function\n\ndef main():\n    print(utility_function())\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls",
      "tree ."
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "execution",
        "target": "main.py",
        "description": "Code should run"
      }
    ],
    "metadata": {
      "scenario_type": "file_ops",
      "command_focus": "cp,mv,mkdir"
    }
  },
  {
    "id": "prompt_000508",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix the CSV processor that fails on the header line.\n\nExplore the data first:\n1. cat data.csv\n2. head -n 1 data.csv (see header)\n3. tail -n +2 data.csv (see data without header)\n4. cut -d',' -f3 data.csv (extract scores)\n5. awk -F',' 'NR>1 {print $3}' data.csv (scores without header)\n\nFix by skipping header:\nsed -i '/for line in f:/a\\        next(f)  # Skip header' processor.py",
    "files": [
      {
        "path": "data.csv",
        "content": "name,age,score\nAlice,25,85\nBob,30,92\nCharlie,22,78\nDavid,35,95\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "\"\"\"Process CSV data.\"\"\"\n\ndef process_data(filename):\n    # BUG: Doesn't handle header correctly\n    total = 0\n    with open(filename) as f:\n        for line in f:\n            parts = line.strip().split(',')\n            total += int(parts[2])  # Will fail on header\n    return total\n",
        "is_test": false
      },
      {
        "path": "test_processor.py",
        "content": "from processor import process_data\n\ndef test_process():\n    result = process_data('data.csv')\n    assert result == 350, f\"Expected 350, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat data.csv | head -3"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_processor.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "awk_cut",
      "command_focus": "awk,cut"
    }
  },
  {
    "id": "prompt_000088",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Fix the broken python code. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers):\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n < 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 == 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 779 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 5"
      ],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000922",
    "difficulty": "medium",
    "language": "python",
    "task_description": "The code has issues that prevent it from working correctly. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers):\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n < 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 != 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 779 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 5",
        "Wrong comparison operator on line 9"
      ],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000278",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Reorganize project structure.\n\nRequired operations:\n1. mkdir lib (create directory)\n2. cp utils.py lib/utils.py (copy file)\n3. sed -i 's/from utils/from lib.utils/g' main.py (update import)\n4. touch lib/__init__.py (make it a package)\n\nThen verify:\n5. ls lib/\n6. cat main.py | grep import",
    "files": [
      {
        "path": "utils.py",
        "content": "def utility_function():\n    return \"util\"\n",
        "is_test": false
      },
      {
        "path": "main.py",
        "content": "from utils import utility_function\n\ndef main():\n    print(utility_function())\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls",
      "tree ."
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "execution",
        "target": "main.py",
        "description": "Code should run"
      }
    ],
    "metadata": {
      "scenario_type": "file_ops",
      "command_focus": "cp,mv,mkdir"
    }
  },
  {
    "id": "prompt_000032",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000726",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "The code has issues that prevent it from working correctly. This is a complex debugging task with multiple related issues. You'll need to understand the architecture and trace dependencies. Start by running tests to see what's failing. Files in project: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers)\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n > 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 == 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 778 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 12,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing colon on line 3"
      ],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000322",
    "difficulty": "hard",
    "language": "python",
    "task_description": "The python project has failing tests. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: algorithms.py, test_algorithms.py",
    "files": [
      {
        "path": "algorithms.py",
        "content": "\"\"\"Algorithm implementations.\"\"\"\n\ndef binary_search(arr, target):\n    \"\"\"Binary search in sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] != target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1\n\ndef bubble_sort(arr):\n    \"\"\"Sort array using bubble sort.\"\"\"\n    n = len(arr)\n    for i in range(n):\n        for j in range(0, n - i - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n\ndef fibonacci(n):\n    \"\"\"Calculate nth Fibonacci number.\"\"\"\n    if n <= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fibonacci(n - 1) + fibonacci(n - 2)\n\ndef factorial(n):\n    \"\"\"Calculate factorial of n.\"\"\"\n    if n == 0 or n == 1:\n        return 1\n    return n * factorial(n - 1)\n",
        "is_test": false
      },
      {
        "path": "test_algorithms.py",
        "content": "\"\"\"Tests for algorithms.\"\"\"\n\nfrom algorithms import binary_search, bubble_sort, fibonacci, factorial\n\ndef test_binary_search():\n    assert binary_search([1, 2, 3, 4, 5], 3) == 2\n    assert binary_search([1, 2, 3, 4, 5], 6) == -1\n    assert binary_search([1], 1) == 0\n\ndef test_bubble_sort():\n    assert bubble_sort([3, 1, 4, 1, 5]) == [1, 1, 3, 4, 5]\n    assert bubble_sort([]) == []\n    assert bubble_sort([1]) == [1]\n\ndef test_fibonacci():\n    assert fibonacci(0) == 0\n    assert fibonacci(1) == 1\n    assert fibonacci(5) == 5\n    assert fibonacci(10) == 55\n\ndef test_factorial():\n    assert factorial(0) == 1\n    assert factorial(1) == 1\n    assert factorial(5) == 120\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 934 Oct 30 10:00 algorithms.py",
      "-rw-r--r-- 1 user user 672 Oct 30 10:00 test_algorithms.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_algorithms.py",
        "description": "All algorithm tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 8"
      ],
      "scenario_type": "algorithms"
    }
  },
  {
    "id": "prompt_000878",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Fix multiple bugs using sed commands.\n\nRequired:\n1. sed -i 's/a - b/a + b/g' calculator.py\n2. sed -i 's/x + y/x * y/g' calculator.py\n3. sed -i '/DEBUG/d' calculator.py (remove debug line)\n4. Add zero check: sed -i '/return a \\/ b/i\\    if b == 0: raise ValueError(\"Division by zero\")' calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Module with multiple bugs.\"\"\"\n\ndef calculate(a, b):\n    # BUG 1: Wrong operator\n    result = a - b  # Should be a + b\n    return result\n\ndef multiply(x, y):\n    # BUG 2: Wrong operator\n    return x + y  # Should be x * y\n\ndef divide(a, b):\n    # BUG 3: Missing check\n    return a / b  # Should check b != 0\n\n# DEBUG CODE TO REMOVE\nprint(\"DEBUG: Loading module\")\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "import pytest\nfrom calculator import calculate, multiply, divide\n\ndef test_calculate():\n    assert calculate(5, 3) == 8\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n\ndef test_divide():\n    assert divide(10, 2) == 5\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000722",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Reorganize project structure.\n\nRequired operations:\n1. mkdir lib (create directory)\n2. cp utils.py lib/utils.py (copy file)\n3. sed -i 's/from utils/from lib.utils/g' main.py (update import)\n4. touch lib/__init__.py (make it a package)\n\nThen verify:\n5. ls lib/\n6. cat main.py | grep import",
    "files": [
      {
        "path": "utils.py",
        "content": "def utility_function():\n    return \"util\"\n",
        "is_test": false
      },
      {
        "path": "main.py",
        "content": "from utils import utility_function\n\ndef main():\n    print(utility_function())\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls",
      "tree ."
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "execution",
        "target": "main.py",
        "description": "Code should run"
      }
    ],
    "metadata": {
      "scenario_type": "file_ops",
      "command_focus": "cp,mv,mkdir"
    }
  },
  {
    "id": "prompt_000964",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Fix log analyzer using piping commands.\n\nAnalyze logs with pipes:\n1. cat server.log | grep ERROR (see errors)\n2. cat server.log | grep ERROR | wc -l (count errors)\n3. cat server.log | cut -d' ' -f4 | sort | uniq (unique levels)\n4. grep ERROR server.log | cut -d' ' -f1-2 (error timestamps)\n\nFix the code:\nsed -i 's/count += 1/if \"ERROR\" in line:\\n                count += 1/g' analyzer.py",
    "files": [
      {
        "path": "server.log",
        "content": "2024-10-30 10:00:00 INFO Server started\n2024-10-30 10:00:01 INFO Connected to database\n2024-10-30 10:00:05 ERROR Failed to load config\n2024-10-30 10:00:10 WARNING Retry attempt 1\n2024-10-30 10:00:15 ERROR Connection timeout\n2024-10-30 10:00:20 INFO Request processed\n2024-10-30 10:00:25 ERROR Database query failed\n",
        "is_test": false
      },
      {
        "path": "analyzer.py",
        "content": "\"\"\"Log analyzer with bug.\"\"\"\n\ndef count_errors(filename):\n    # BUG: Counts all lines, not just errors\n    count = 0\n    with open(filename) as f:\n        for line in f:\n            count += 1  # Should filter for ERROR\n    return count\n",
        "is_test": false
      },
      {
        "path": "test_analyzer.py",
        "content": "from analyzer import count_errors\n\ndef test_count():\n    result = count_errors('server.log')\n    assert result == 3, f\"Expected 3 errors, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "head server.log"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_analyzer.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "piping",
      "command_focus": "pipes"
    }
  },
  {
    "id": "prompt_000769",
    "difficulty": "medium",
    "language": "javascript",
    "task_description": "Fix bugs with multiple sed commands.\n\nUse:\n1. sed -i 's/a - b/a + b/g' calculator.js\n2. sed -i 's/x + y/x \\* y/g' calculator.js\n3. sed -i '/DEBUG/d' calculator.js",
    "files": [
      {
        "path": "calculator.js",
        "content": "// Module with bugs\n\nfunction calculate(a, b) {\n    // BUG: Wrong operator\n    return a - b;  // Should be a + b\n}\n\nfunction multiply(x, y) {\n    // BUG: Wrong operator\n    return x + y;  // Should be x * y\n}\n\n// DEBUG\nconsole.log(\"DEBUG: Loading\");\n\nmodule.exports = { calculate, multiply };\n",
        "is_test": false
      },
      {
        "path": "test_calculator.js",
        "content": "const { calculate, multiply } = require('./calculator');\n\nif (calculate(5, 3) !== 8) throw new Error(\"calculate failed\");\nif (multiply(4, 5) !== 20) throw new Error(\"multiply failed\");\nconsole.log(\"\u2713 All tests passed\");\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.js",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000801",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Process text file using transformation commands.\n\nCommands to explore:\n1. cat words.txt | tr 'A-Z' 'a-z' (lowercase)\n2. cat words.txt | tr 'A-Z' 'a-z' | sort (sorted)\n3. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq (unique)\n4. cat words.txt | tr 'A-Z' 'a-z' | sort | uniq | wc -l (count)\n\nFix code to be case-insensitive:\nsed -i 's/f.read().split()/f.read().lower().split()/g' processor.py",
    "files": [
      {
        "path": "words.txt",
        "content": "apple\nbanana\napple\nCherry\nbanana\nApple\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "def process():\n    # BUG: Case-sensitive duplicates\n    with open('words.txt') as f:\n        return list(set(f.read().split()))\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "cat words.txt"
    ],
    "expected_commands": 7,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "processor.py",
        "description": "Uses lowercase"
      }
    ],
    "metadata": {
      "scenario_type": "text_transform",
      "command_focus": "tr,sort,uniq"
    }
  },
  {
    "id": "prompt_000929",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000119",
    "difficulty": "easy",
    "language": "javascript",
    "task_description": "The code has issues that prevent it from working correctly. The issue is straightforward - locate the problem and fix it. Files: validators.js, test_validators.js",
    "files": [
      {
        "path": "validators.js",
        "content": "// Validation functions\n\nfunction isValidEmail(email) \n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n}\n\nfunction isValidPhone(phone) {\n    const regex = /^\\d{3}-\\d{3}-\\d{4}$/;\n    return regex.test(phone);\n}\n\nfunction isValidPassword(password) {\n    return password.length >= 8;\n}\n\nfunction isValidUsername(username) {\n    const regex = /^[a-zA-Z0-9_]{3,20}$/;\n    return regex.test(username);\n}\n\nmodule.exports = { isValidEmail, isValidPhone, isValidPassword, isValidUsername };\n",
        "is_test": false
      },
      {
        "path": "test_validators.js",
        "content": "// Tests for validators\n\nconst { isValidEmail, isValidPhone, isValidPassword, isValidUsername } = require('./validators');\n\nfunction assertEquals(actual, expected, message) {\n    if (actual !== expected) {\n        throw new Error(`${message}: expected ${expected}, got ${actual}`);\n    }\n}\n\nfunction test_isValidEmail() {\n    assertEquals(isValidEmail(\"user@example.com\"), true, \"valid email\");\n    assertEquals(isValidEmail(\"invalid\"), false, \"invalid email\");\n    console.log(\"\u2713 test_isValidEmail passed\");\n}\n\nfunction test_isValidPhone() {\n    assertEquals(isValidPhone(\"123-456-7890\"), true, \"valid phone\");\n    assertEquals(isValidPhone(\"1234567890\"), false, \"invalid phone\");\n    console.log(\"\u2713 test_isValidPhone passed\");\n}\n\nfunction test_isValidPassword() {\n    assertEquals(isValidPassword(\"password123\"), true, \"valid password\");\n    assertEquals(isValidPassword(\"short\"), false, \"invalid password\");\n    console.log(\"\u2713 test_isValidPassword passed\");\n}\n\nfunction test_isValidUsername() {\n    assertEquals(isValidUsername(\"user_123\"), true, \"valid username\");\n    assertEquals(isValidUsername(\"ab\"), false, \"too short username\");\n    console.log(\"\u2713 test_isValidUsername passed\");\n}\n\n// Run all tests\ntry {\n    test_isValidEmail();\n    test_isValidPhone();\n    test_isValidPassword();\n    test_isValidUsername();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls",
      "validators.js test_validators.js"
    ],
    "expected_commands": 3,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_validators.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Missing opening brace on line 3"
      ],
      "scenario_type": "validators"
    }
  },
  {
    "id": "prompt_000609",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix the broken python code. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers)\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n < 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 == 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 778 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 5",
        "Missing colon on line 3"
      ],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000191",
    "difficulty": "medium",
    "language": "javascript",
    "task_description": "The javascript project has failing tests. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: array_ops.js, test_array_ops.js",
    "files": [
      {
        "path": "array_ops.js",
        "content": "// Array operation functions\n\nfunction sum(arr) {\n    return arr.reduce((a, b) => a + b, 0);\n}\n\nfunction findMax(arr) {\n    if (arr.length !== 0) return null;\n    return Math.max(...arr);\n}\n\nfunction removeDuplicates(arr) {\n    return [...new Set(arr)];\n}\n\nfunction flatten(arr) {\n    return arr.flat();\n}\n\nfunction chunk(arr, size) {\n    const result = [];\n    for (let i = 0; i < arr.length; i += size) {\n        result.push(arr.slice(i, i + size));\n    }\n    return result;\n}\n\nmodule.exports = { sum, findMax, removeDuplicates, flatten, chunk };\n",
        "is_test": false
      },
      {
        "path": "test_array_ops.js",
        "content": "// Tests for array operations\n\nconst { sum, findMax, removeDuplicates, flatten, chunk } = require('./array_ops');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_sum() {\n    assertEquals(sum([1, 2, 3, 4, 5]), 15, \"sum([1, 2, 3, 4, 5])\");\n    assertEquals(sum([]), 0, \"sum([])\");\n    console.log(\"\u2713 test_sum passed\");\n}\n\nfunction test_findMax() {\n    assertEquals(findMax([1, 5, 3, 9, 2]), 9, \"findMax([1, 5, 3, 9, 2])\");\n    assertEquals(findMax([]), null, \"findMax([])\");\n    console.log(\"\u2713 test_findMax passed\");\n}\n\nfunction test_removeDuplicates() {\n    assertEquals(removeDuplicates([1, 2, 2, 3, 1, 4]), [1, 2, 3, 4], \"removeDuplicates\");\n    console.log(\"\u2713 test_removeDuplicates passed\");\n}\n\nfunction test_flatten() {\n    assertEquals(flatten([[1, 2], [3, 4], [5]]), [1, 2, 3, 4, 5], \"flatten\");\n    console.log(\"\u2713 test_flatten passed\");\n}\n\nfunction test_chunk() {\n    assertEquals(chunk([1, 2, 3, 4, 5], 2), [[1, 2], [3, 4], [5]], \"chunk\");\n    console.log(\"\u2713 test_chunk passed\");\n}\n\n// Run all tests\ntry {\n    test_sum();\n    test_findMax();\n    test_removeDuplicates();\n    test_flatten();\n    test_chunk();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 549 Oct 30 10:00 array_ops.js",
      "-rw-r--r-- 1 user user 1435 Oct 30 10:00 test_array_ops.js"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_array_ops.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 8"
      ],
      "scenario_type": "array_ops"
    }
  },
  {
    "id": "prompt_000398",
    "difficulty": "medium",
    "language": "python",
    "task_description": "The code has issues that prevent it from working correctly. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: data_processor.py, test_data_processor.py",
    "files": [
      {
        "path": "data_processor.py",
        "content": "\"\"\"Data processing utilities.\"\"\"\n\ndef filter_positive(numbers):\n    \"\"\"Filter positive numbers from a list.\"\"\"\n    return [n for n in numbers if n > 0]\n\ndef sum_even(numbers):\n    \"\"\"Sum all even numbers in a list.\"\"\"\n    return sum(n for n in numbers if n % 2 == 0)\n\ndef find_max(numbers):\n    \"\"\"Find maximum value in a list.\"\"\"\n    if not numbers:\n        return None\n    return max(numbers)\n\ndef average(numbers):\n    \"\"\"Calculate average of numbers.\"\"\"\n    if not numbers:\n        return 0\n    return sum(numbers) / len(numbers)\n\ndef remove_duplicates(items):\n    \"\"\"Remove duplicates while preserving order.\"\"\"\n    seen = set()\n    result = []\n    for item in items:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n",
        "is_test": false
      },
      {
        "path": "test_data_processor.py",
        "content": "\"\"\"Tests for data processor.\"\"\"\n\nfrom data_processor import filter_positive, sum_even, find_max, average, remove_duplicates\n\ndef test_filter_positive():\n    assert filter_positive([1, -2, 3, -4, 5]) == [1, 3, 5]\n    assert filter_positive([-1, -2, -3]) == []\n    assert filter_positive([]) == []\n\ndef test_sum_even():\n    assert sum_even([1, 2, 3, 4, 5, 6]) == 12\n    assert sum_even([1, 3, 5]) == 0\n\ndef test_find_max():\n    assert find_max([1, 5, 3, 9, 2]) == 9\n    assert find_max([-5, -1, -10]) == -1\n    assert find_max([]) is None\n\ndef test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n\ndef test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4]\n    assert remove_duplicates([]) == []\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 779 Oct 30 10:00 data_processor.py",
      "-rw-r--r-- 1 user user 797 Oct 30 10:00 test_data_processor.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_data_processor.py",
        "description": "All data processor tests must pass"
      }
    ],
    "metadata": {
      "bugs": [],
      "scenario_type": "data_processor"
    }
  },
  {
    "id": "prompt_000620",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Analyze web server logs using various commands.\n\nRequired analysis:\n1. grep \"404\\|500\" access.log (find errors)\n2. cut -d' ' -f1 access.log | sort | uniq (unique IPs)\n3. awk '{print $9}' access.log | sort | uniq -c (status code counts)\n4. grep \"GET\" access.log | wc -l (count GET requests)\n5. cat access.log | cut -d'\"' -f2 | cut -d' ' -f2 (extract paths)\n\nCreate summary:\necho \"Error count: $(grep -c '404\\|500' access.log)\" > summary.txt",
    "files": [
      {
        "path": "access.log",
        "content": "192.168.1.1 - - [30/Oct/2024:10:00:00] \"GET /api/users HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:01] \"POST /api/data HTTP/1.1\" 201\n192.168.1.1 - - [30/Oct/2024:10:00:05] \"GET /api/users HTTP/1.1\" 404\n192.168.1.3 - - [30/Oct/2024:10:00:10] \"GET /api/items HTTP/1.1\" 200\n192.168.1.2 - - [30/Oct/2024:10:00:15] \"DELETE /api/data HTTP/1.1\" 500\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "head -3 access.log"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "summary.txt",
        "description": "Summary created"
      }
    ],
    "metadata": {
      "scenario_type": "log_analysis",
      "command_focus": "awk,cut,grep,pipes"
    }
  },
  {
    "id": "prompt_000584",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "Fix the broken javascript code. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: array_ops.js, test_array_ops.js",
    "files": [
      {
        "path": "array_ops.js",
        "content": "// Array operation functions\n\nfunction sum(arr) \n    return arr.reduce((a, b) => a - b, 0);\n}\n\nfunction findMax(arr) {\n    if (arr.length !== 0) return null;\n    return Math.max(...arr);\n}\n\nfunction removeDuplicates(arr) {\n    return [...new Set(arr)];\n}\n\nfunction flatten(arr) {\n    return arr.flat();\n}\n\nfunction chunk(arr, size) {\n    const result = [];\n    for (let i = 0; i < arr.length; i += size) {\n        result.push(arr.slice(i, i + size));\n    }\n    return result;\n}\n\nmodule.exports = { sum, findMax, removeDuplicates, flatten, chunk };\n",
        "is_test": false
      },
      {
        "path": "test_array_ops.js",
        "content": "// Tests for array operations\n\nconst { sum, findMax, removeDuplicates, flatten, chunk } = require('./array_ops');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_sum() {\n    assertEquals(sum([1, 2, 3, 4, 5]), 15, \"sum([1, 2, 3, 4, 5])\");\n    assertEquals(sum([]), 0, \"sum([])\");\n    console.log(\"\u2713 test_sum passed\");\n}\n\nfunction test_findMax() {\n    assertEquals(findMax([1, 5, 3, 9, 2]), 9, \"findMax([1, 5, 3, 9, 2])\");\n    assertEquals(findMax([]), null, \"findMax([])\");\n    console.log(\"\u2713 test_findMax passed\");\n}\n\nfunction test_removeDuplicates() {\n    assertEquals(removeDuplicates([1, 2, 2, 3, 1, 4]), [1, 2, 3, 4], \"removeDuplicates\");\n    console.log(\"\u2713 test_removeDuplicates passed\");\n}\n\nfunction test_flatten() {\n    assertEquals(flatten([[1, 2], [3, 4], [5]]), [1, 2, 3, 4, 5], \"flatten\");\n    console.log(\"\u2713 test_flatten passed\");\n}\n\nfunction test_chunk() {\n    assertEquals(chunk([1, 2, 3, 4, 5], 2), [[1, 2], [3, 4], [5]], \"chunk\");\n    console.log(\"\u2713 test_chunk passed\");\n}\n\n// Run all tests\ntry {\n    test_sum();\n    test_findMax();\n    test_removeDuplicates();\n    test_flatten();\n    test_chunk();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 548 Oct 30 10:00 array_ops.js",
      "-rw-r--r-- 1 user user 1435 Oct 30 10:00 test_array_ops.js",
      "$ node test_array_ops.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_array_ops.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong arithmetic operator on line 4",
        "Missing opening brace on line 3",
        "Wrong comparison operator on line 8"
      ],
      "scenario_type": "array_ops"
    }
  },
  {
    "id": "prompt_000169",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Use git to track changes.\n\nWorkflow:\n1. git init (initialize repo)\n2. git add feature.py (stage file)\n3. git commit -m \"Initial commit\" (commit)\n4. sed -i 's/v1/v2/g' feature.py (make change)\n5. git diff (see changes)\n6. git add feature.py (stage changes)\n7. git commit -m \"Update to v2\"\n8. git log --oneline (view history)",
    "files": [
      {
        "path": "feature.py",
        "content": "def feature():\n    return \"v1\"  # Update to v2\n",
        "is_test": false
      }
    ],
    "cli_history": [],
    "expected_commands": 10,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "feature.py",
        "description": "Version updated"
      }
    ],
    "metadata": {
      "scenario_type": "git",
      "command_focus": "git"
    }
  },
  {
    "id": "prompt_000862",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Fix multiple bugs using sed commands.\n\nRequired:\n1. sed -i 's/a - b/a + b/g' calculator.py\n2. sed -i 's/x + y/x * y/g' calculator.py\n3. sed -i '/DEBUG/d' calculator.py (remove debug line)\n4. Add zero check: sed -i '/return a \\/ b/i\\    if b == 0: raise ValueError(\"Division by zero\")' calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Module with multiple bugs.\"\"\"\n\ndef calculate(a, b):\n    # BUG 1: Wrong operator\n    result = a - b  # Should be a + b\n    return result\n\ndef multiply(x, y):\n    # BUG 2: Wrong operator\n    return x + y  # Should be x * y\n\ndef divide(a, b):\n    # BUG 3: Missing check\n    return a / b  # Should check b != 0\n\n# DEBUG CODE TO REMOVE\nprint(\"DEBUG: Loading module\")\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "import pytest\nfrom calculator import calculate, multiply, divide\n\ndef test_calculate():\n    assert calculate(5, 3) == 8\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n\ndef test_divide():\n    assert divide(10, 2) == 5\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat calculator.*"
    ],
    "expected_commands": 5,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "Tests must pass"
      }
    ],
    "metadata": {
      "scenario_type": "sed_intensive",
      "command_focus": "sed"
    }
  },
  {
    "id": "prompt_000547",
    "difficulty": "medium",
    "language": "python",
    "task_description": "Fix the CSV processor that fails on the header line.\n\nExplore the data first:\n1. cat data.csv\n2. head -n 1 data.csv (see header)\n3. tail -n +2 data.csv (see data without header)\n4. cut -d',' -f3 data.csv (extract scores)\n5. awk -F',' 'NR>1 {print $3}' data.csv (scores without header)\n\nFix by skipping header:\nsed -i '/for line in f:/a\\        next(f)  # Skip header' processor.py",
    "files": [
      {
        "path": "data.csv",
        "content": "name,age,score\nAlice,25,85\nBob,30,92\nCharlie,22,78\nDavid,35,95\n",
        "is_test": false
      },
      {
        "path": "processor.py",
        "content": "\"\"\"Process CSV data.\"\"\"\n\ndef process_data(filename):\n    # BUG: Doesn't handle header correctly\n    total = 0\n    with open(filename) as f:\n        for line in f:\n            parts = line.strip().split(',')\n            total += int(parts[2])  # Will fail on header\n    return total\n",
        "is_test": false
      },
      {
        "path": "test_processor.py",
        "content": "from processor import process_data\n\ndef test_process():\n    result = process_data('data.csv')\n    assert result == 350, f\"Expected 350, got {result}\"\n    print(\"\u2713 Test passed\")\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "ls",
      "cat data.csv | head -3"
    ],
    "expected_commands": 8,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_processor.py",
        "description": "Test must pass"
      }
    ],
    "metadata": {
      "scenario_type": "awk_cut",
      "command_focus": "awk,cut"
    }
  },
  {
    "id": "prompt_000641",
    "difficulty": "very_hard",
    "language": "python",
    "task_description": "Use git to track changes.\n\nWorkflow:\n1. git init (initialize repo)\n2. git add feature.py (stage file)\n3. git commit -m \"Initial commit\" (commit)\n4. sed -i 's/v1/v2/g' feature.py (make change)\n5. git diff (see changes)\n6. git add feature.py (stage changes)\n7. git commit -m \"Update to v2\"\n8. git log --oneline (view history)",
    "files": [
      {
        "path": "feature.py",
        "content": "def feature():\n    return \"v1\"  # Update to v2\n",
        "is_test": false
      }
    ],
    "cli_history": [],
    "expected_commands": 10,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "feature.py",
        "description": "Version updated"
      }
    ],
    "metadata": {
      "scenario_type": "git",
      "command_focus": "git"
    }
  },
  {
    "id": "prompt_000384",
    "difficulty": "hard",
    "language": "python",
    "task_description": "Refactor: rename old_function to new_function everywhere.\n\nCommands needed:\n1. grep -r \"old_function\" . (find all occurrences)\n2. find . -name \"*.py\" (find all Python files)\n3. sed -i 's/old_function/new_function/g' module1.py\n4. sed -i 's/old_function/new_function/g' module2.py\n5. grep -r \"new_function\" . (verify changes)\n\nOr use find with xargs:\nfind . -name \"*.py\" -exec sed -i 's/old_function/new_function/g' {} \\;",
    "files": [
      {
        "path": "module1.py",
        "content": "def old_function():\n    return \"old\"\n",
        "is_test": false
      },
      {
        "path": "module2.py",
        "content": "from module1 import old_function\n\ndef caller():\n    return old_function()\n",
        "is_test": false
      }
    ],
    "cli_history": [
      "ls *.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "text_match",
        "target": "module1.py",
        "description": "Renamed"
      }
    ],
    "metadata": {
      "scenario_type": "refactoring",
      "command_focus": "find,xargs,sed"
    }
  },
  {
    "id": "prompt_000347",
    "difficulty": "medium",
    "language": "python",
    "task_description": "The python project has failing tests. You'll need to explore the codebase to find the issue. Check the test failures for clues. Project structure: calculator.py, test_calculator.py",
    "files": [
      {
        "path": "calculator.py",
        "content": "\"\"\"Simple calculator module.\"\"\"\n\ndef add(a, b):\n    \"\"\"Add two numbers.\"\"\"\n    return a - b\n\ndef subtract(a, b):\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\ndef power(a, b):\n    \"\"\"Calculate a to the power of b.\"\"\"\n    return a ** b\n",
        "is_test": false
      },
      {
        "path": "test_calculator.py",
        "content": "\"\"\"Tests for calculator module.\"\"\"\n\nimport pytest\nfrom calculator import add, subtract, multiply, divide, power\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n\ndef test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(0, 5) == -5\n\ndef test_multiply():\n    assert multiply(4, 5) == 20\n    assert multiply(-2, 3) == -6\n\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ValueError):\n        divide(5, 0)\n\ndef test_power():\n    assert power(2, 3) == 8\n    assert power(5, 0) == 1\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 432 Oct 30 10:00 calculator.py",
      "-rw-r--r-- 1 user user 593 Oct 30 10:00 test_calculator.py"
    ],
    "expected_commands": 6,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_calculator.py",
        "description": "All calculator tests must pass"
      },
      {
        "type": "lint",
        "target": "calculator.py",
        "description": "Code must pass basic linting"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong arithmetic operator on line 5"
      ],
      "scenario_type": "calculator"
    }
  },
  {
    "id": "prompt_000031",
    "difficulty": "hard",
    "language": "python",
    "task_description": "There's a bug in the python code that needs fixing. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: string_utils.py, test_string_utils.py",
    "files": [
      {
        "path": "string_utils.py",
        "content": "\"\"\"String utility functions.\"\"\"\n\ndef reverse_string(s):\n    \"\"\"Reverse a string.\"\"\"\n    return s[::-1]\n\ndef is_palindrome(s):\n    \"\"\"Check if string is a palindrome.\"\"\"\n    cleaned = s.lower().replace(\" \", \"\")\n    return cleaned != cleaned[::-1]\n\ndef count_vowels(s):\n    \"\"\"Count vowels in a string.\"\"\"\n    vowels = \"aeiouAEIOU\"\n    return sum(1 for char in s if char in vowels)\n\ndef capitalize_words(s):\n    \"\"\"Capitalize first letter of each word.\"\"\"\n    return \" \".join(word.capitalize() for word in s.split())\n\ndef remove_whitespace(s):\n    \"\"\"Remove all whitespace from string.\"\"\"\n    return \"\".join(s.split())\n",
        "is_test": false
      },
      {
        "path": "test_string_utils.py",
        "content": "\"\"\"Tests for string utilities.\"\"\"\n\nfrom string_utils import reverse_string, is_palindrome, count_vowels, capitalize_words, remove_whitespace\n\ndef test_reverse_string():\n    assert reverse_string(\"hello\") == \"olleh\"\n    assert reverse_string(\"\") == \"\"\n    assert reverse_string(\"a\") == \"a\"\n\ndef test_is_palindrome():\n    assert is_palindrome(\"racecar\") == True\n    assert is_palindrome(\"hello\") == False\n    assert is_palindrome(\"A man a plan a canal Panama\") == True\n\ndef test_count_vowels():\n    assert count_vowels(\"hello\") == 2\n    assert count_vowels(\"AEIOU\") == 5\n    assert count_vowels(\"xyz\") == 0\n\ndef test_capitalize_words():\n    assert capitalize_words(\"hello world\") == \"Hello World\"\n    assert capitalize_words(\"python programming\") == \"Python Programming\"\n\ndef test_remove_whitespace():\n    assert remove_whitespace(\"hello world\") == \"helloworld\"\n    assert remove_whitespace(\"  a  b  c  \") == \"abc\"\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 617 Oct 30 10:00 string_utils.py",
      "-rw-r--r-- 1 user user 913 Oct 30 10:00 test_string_utils.py",
      "$ pytest -v",
      "test_*.py::test_* FAILED",
      "Some tests are failing..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "test",
        "target": "test_string_utils.py",
        "description": "All string utility tests must pass"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong comparison operator on line 10"
      ],
      "scenario_type": "string_utils"
    }
  },
  {
    "id": "prompt_000860",
    "difficulty": "hard",
    "language": "javascript",
    "task_description": "Fix the broken javascript code. Multiple issues may need to be resolved. Carefully examine the test output and trace through the code. The project has these files: array_ops.js, test_array_ops.js",
    "files": [
      {
        "path": "array_ops.js",
        "content": "// Array operation functions\n\nfunction sum(arr) \n    return arr.reduce((a, b) => a - b, 0);\n}\n\nfunction findMax(arr) {\n    if (arr.length === 0) return null;\n    return Math.max(...arr);\n}\n\nfunction removeDuplicates(arr) {\n    return [...new Set(arr)];\n}\n\nfunction flatten(arr) {\n    return arr.flat();\n}\n\nfunction chunk(arr, size) {\n    const result = [];\n    for (let i = 0; i < arr.length; i += size) {\n        result.push(arr.slice(i, i + size));\n    }\n    return result;\n}\n\nmodule.exports = { sum, findMax, removeDuplicates, flatten, chunk };\n",
        "is_test": false
      },
      {
        "path": "test_array_ops.js",
        "content": "// Tests for array operations\n\nconst { sum, findMax, removeDuplicates, flatten, chunk } = require('./array_ops');\n\nfunction assertEquals(actual, expected, message) {\n    if (JSON.stringify(actual) !== JSON.stringify(expected)) {\n        throw new Error(`${message}: expected ${JSON.stringify(expected)}, got ${JSON.stringify(actual)}`);\n    }\n}\n\nfunction test_sum() {\n    assertEquals(sum([1, 2, 3, 4, 5]), 15, \"sum([1, 2, 3, 4, 5])\");\n    assertEquals(sum([]), 0, \"sum([])\");\n    console.log(\"\u2713 test_sum passed\");\n}\n\nfunction test_findMax() {\n    assertEquals(findMax([1, 5, 3, 9, 2]), 9, \"findMax([1, 5, 3, 9, 2])\");\n    assertEquals(findMax([]), null, \"findMax([])\");\n    console.log(\"\u2713 test_findMax passed\");\n}\n\nfunction test_removeDuplicates() {\n    assertEquals(removeDuplicates([1, 2, 2, 3, 1, 4]), [1, 2, 3, 4], \"removeDuplicates\");\n    console.log(\"\u2713 test_removeDuplicates passed\");\n}\n\nfunction test_flatten() {\n    assertEquals(flatten([[1, 2], [3, 4], [5]]), [1, 2, 3, 4, 5], \"flatten\");\n    console.log(\"\u2713 test_flatten passed\");\n}\n\nfunction test_chunk() {\n    assertEquals(chunk([1, 2, 3, 4, 5], 2), [[1, 2], [3, 4], [5]], \"chunk\");\n    console.log(\"\u2713 test_chunk passed\");\n}\n\n// Run all tests\ntry {\n    test_sum();\n    test_findMax();\n    test_removeDuplicates();\n    test_flatten();\n    test_chunk();\n    console.log(\"All tests passed!\");\n} catch (e) {\n    console.error(\"Test failed:\", e.message);\n    process.exit(1);\n}\n",
        "is_test": true
      }
    ],
    "cli_history": [
      "$ ls -la",
      "-rw-r--r-- 1 user user 548 Oct 30 10:00 array_ops.js",
      "-rw-r--r-- 1 user user 1435 Oct 30 10:00 test_array_ops.js",
      "$ node test_array_ops.js",
      "Test failed: ..."
    ],
    "expected_commands": 9,
    "verification_rules": [
      {
        "type": "execution",
        "target": "test_array_ops.js",
        "description": "Tests must run successfully"
      }
    ],
    "metadata": {
      "bugs": [
        "Wrong arithmetic operator on line 4",
        "Missing opening brace on line 3"
      ],
      "scenario_type": "array_ops"
    }
  }
]